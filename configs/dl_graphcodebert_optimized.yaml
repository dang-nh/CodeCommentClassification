model_name: "microsoft/graphcodebert-base"
tokenizer_name: "microsoft/graphcodebert-base"
num_labels: 16
max_len: 128
precision: "fp16"
gradient_checkpointing: false
use_single_split: false

peft:
  enabled: true
  r: 64
  alpha: 128
  dropout: 0.1

loss_type: "asl"
loss_params:
  gamma_pos: 0
  gamma_neg: 4
  clip: 0.05

train_params:
  batch_size: 32
  grad_accum: 1
  epochs: 15
  lr: 0.0003
  scheduler: "cosine"
  warmup: 0.1
  weight_decay: 0.01
  seed: 42

data:
  raw_path: "data/raw/sentences.csv"
  processed_path: "data/processed/"
  split_file: "data/processed/splits.json"
  label_list_file: "data/processed/labels.json"

eval:
  metrics: ["precision", "recall", "f1", "roc_auc"]
  threshold_search: true

logging:
  output_dir: "runs/"
  save_every: 1
  early_stop: 5
  tensorboard: false

